{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "+ The following modules need to be installed in order for the code to execute properly\n",
    "    + keras\n",
    "    + tensorflow\n",
    "    \n",
    "+ Useful links\n",
    "    + https://github.com/keras-team/keras/tree/master/examples  -> examples of network architecture\n",
    "    + https://elitedatascience.com/keras-tutorial-deep-learning-in-python -> keras tutorial with mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempts with core layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils        import np_utils\n",
    "from keras.models       import Sequential\n",
    "from keras.layers       import Dense, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, BatchNormalization\n",
    "from keras.datasets     import mnist\n",
    "from keras.optimizers   import Adam, Adadelta\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First very minimal NN -> reaches 97.5% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data from dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape x in 1D\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)\n",
    "\n",
    "# cast x to float32 and normalize to [0,1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(y_train[0])\n",
    "# reshape y to 10-dim bit instead of int\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "print(y_train[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784, activation='sigmoid'))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(24))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# print(model.output_shape)\n",
    "opt = Adam(lr = 0.01)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "         epochs = 8,\n",
    "         batch_size = 32)\n",
    "score = model.evaluate(x_test, y_test, batch_size = 32)\n",
    "print(score)\n",
    "\n",
    "failed = np.nonzero(model.predict_class(x_test).reshape((-1,)) != y_test)\n",
    "for i in range(10):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt using convolutionnal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape in 2D, 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "#convert to float and normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# reshape y to 10-dim bit instead of int\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "opt = Adam(lr = 0.01)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "         epochs = 8,\n",
    "         batch_size = 32)\n",
    "score = model.evaluate(x_test, y_test, batch_size = 32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's improve it by adding some data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape in 2D, 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "#convert to float and normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# reshape y to 10-dim bit instead of int\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=11, width_shift_range=0.14, shear_range=0.25,\n",
    "                         height_shift_range=0.14, zoom_range=0.12)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(x_test, y_test, batch_size=64)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "opt = Adam(lr = 0.01)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "score = model.evaluate(x_test, y_test, batch_size = 64)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more conv2D layers, with more filters to improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 318s 339ms/step - loss: 0.4818 - acc: 0.8460 - val_loss: 0.0584 - val_acc: 0.9829\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 329s 351ms/step - loss: 0.1886 - acc: 0.9436 - val_loss: 0.0418 - val_acc: 0.9863\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 317s 339ms/step - loss: 0.1493 - acc: 0.9556 - val_loss: 0.0332 - val_acc: 0.9892\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 318s 340ms/step - loss: 0.1290 - acc: 0.9613 - val_loss: 0.0317 - val_acc: 0.9905\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 321s 342ms/step - loss: 0.1184 - acc: 0.9643 - val_loss: 0.0285 - val_acc: 0.9909\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 326s 348ms/step - loss: 0.1114 - acc: 0.9672 - val_loss: 0.0298 - val_acc: 0.9900\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 327s 349ms/step - loss: 0.1091 - acc: 0.9684 - val_loss: 0.0317 - val_acc: 0.9907\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 329s 351ms/step - loss: 0.1035 - acc: 0.9701 - val_loss: 0.0289 - val_acc: 0.9909\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 323s 344ms/step - loss: 0.1005 - acc: 0.9708 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 326s 348ms/step - loss: 0.1005 - acc: 0.9705 - val_loss: 0.0398 - val_acc: 0.9883\n",
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "[0.039691976184088706, 0.9883]\n"
     ]
    }
   ],
   "source": [
    "# read data from dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape in 2D, 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "#convert to float and normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# reshape y to 10-dim bit instead of int\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=11, width_shift_range=0.14, shear_range=0.25,\n",
    "                         height_shift_range=0.14, zoom_range=0.12)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(x_test, y_test, batch_size=64)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#opt = Adam(lr = 0.015)\n",
    "opt = Adadelta()\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=10, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "score = model.evaluate(x_test, y_test, batch_size = 64)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"here\")\n",
    "\n",
    "failed = np.nonzero(model.predict_classes(x_test).reshape((-1,)) != np.nonzero(y_test))\n",
    "\n",
    "print(failed)\n",
    "for fail in failed[:25]:\n",
    "    img = x_test[fail].reshape(28, 28)\n",
    "    plt.imshow(img)\n",
    "    print(\"predicted %s ; real value is %s\" % (model.predict_classes(x_test[fail]), y_test[fail]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hello)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
